// Generated by CoffeeScript 1.12.4
(function() {
  var BSON, COUNT, DAYS, DOCUMENT_PACK_DELAY, LIMIT, LockManager, Metrics, ObjectId, ObjectIdFromDate, PackManager, Settings, TIMEOUT, TOTAL, _, async, db, doc_id, file, finish, fs, line, logger, oneWeekAgo, pending, processUpdates, project_id, ref, ref1, result, shutDownRequested, shutDownTimer, source;

  Settings = require("settings-sharelatex");

  async = require("async");

  _ = require("underscore");

  ref = require("./mongojs"), db = ref.db, ObjectId = ref.ObjectId, BSON = ref.BSON;

  fs = require("fs");

  Metrics = require("metrics-sharelatex");

  Metrics.initialize("track-changes");

  logger = require("logger-sharelatex");

  logger.initialize("track-changes-packworker");

  if (((ref1 = Settings.sentry) != null ? ref1.dsn : void 0) != null) {
    logger.initializeErrorReporting(Settings.sentry.dsn);
  }

  DAYS = 24 * 3600 * 1000;

  LockManager = require("./LockManager");

  PackManager = require("./PackManager");

  source = process.argv[2];

  DOCUMENT_PACK_DELAY = Number(process.argv[3]) || 1000;

  TIMEOUT = Number(process.argv[4]) || 30 * 60 * 1000;

  COUNT = 0;

  TOTAL = 0;

  if (!source.match(/^[0-9]+$/)) {
    file = fs.readFileSync(source);
    result = (function() {
      var i, len, ref2, ref3, results1;
      ref2 = file.toString().split('\n');
      results1 = [];
      for (i = 0, len = ref2.length; i < len; i++) {
        line = ref2[i];
        ref3 = line.split(' '), project_id = ref3[0], doc_id = ref3[1];
        results1.push({
          doc_id: doc_id,
          project_id: project_id
        });
      }
      return results1;
    })();
    pending = _.filter(result, function(row) {
      var ref2;
      return row != null ? (ref2 = row.doc_id) != null ? ref2.match(/^[a-f0-9]{24}$/) : void 0 : void 0;
    });
  } else {
    LIMIT = Number(process.argv[2]) || 1000;
  }

  shutDownRequested = false;

  shutDownTimer = setTimeout(function() {
    var hardTimeout;
    logger.log("pack timed out, requesting shutdown");
    shutDownRequested = true;
    hardTimeout = setTimeout(function() {
      logger.error("HARD TIMEOUT in pack archive worker");
      return process.exit();
    }, 5 * 60 * 1000);
    return hardTimeout.unref();
  }, TIMEOUT);

  logger.log("checking for updates, limit=" + LIMIT + ", delay=" + DOCUMENT_PACK_DELAY + ", timeout=" + TIMEOUT);

  db.close = function(callback) {
    return this._getServer(function(err, server) {
      if (err != null) {
        return callback(err);
      }
      server = server.destroy != null ? server : server.topology;
      server.destroy(true, true);
      return callback();
    });
  };

  finish = function() {
    if (shutDownTimer != null) {
      logger.log('cancelling timeout');
      clearTimeout(shutDownTimer);
    }
    logger.log('closing db');
    return db.close(function() {
      logger.log('closing LockManager Redis Connection');
      return LockManager.close(function() {
        var hardTimeout;
        logger.log({
          processedCount: COUNT,
          allCount: TOTAL
        }, 'ready to exit from pack archive worker');
        hardTimeout = setTimeout(function() {
          logger.error('hard exit from pack archive worker');
          return process.exit(1);
        }, 5 * 1000);
        return hardTimeout.unref();
      });
    });
  };

  process.on('exit', function(code) {
    return logger.log({
      code: code
    }, 'pack archive worker exited');
  });

  processUpdates = function(pending) {
    return async.eachSeries(pending, function(result, callback) {
      var _id, handler;
      _id = result._id, project_id = result.project_id, doc_id = result.doc_id;
      COUNT++;
      logger.log({
        project_id: project_id,
        doc_id: doc_id
      }, "processing " + COUNT + "/" + TOTAL);
      if ((project_id == null) || (doc_id == null)) {
        logger.log({
          project_id: project_id,
          doc_id: doc_id
        }, "skipping pack, missing project/doc id");
        return callback();
      }
      handler = function(err, result) {
        if ((err != null) && err.code === "InternalError" && err.retryable) {
          logger.warn({
            err: err,
            result: result
          }, "ignoring S3 error in pack archive worker");
          err = null;
        }
        if (err != null) {
          logger.error({
            err: err,
            result: result
          }, "error in pack archive worker");
          return callback(err);
        }
        if (shutDownRequested) {
          logger.warn("shutting down pack archive worker");
          return callback(new Error("shutdown"));
        }
        return setTimeout(function() {
          return callback(err, result);
        }, DOCUMENT_PACK_DELAY);
      };
      if (_id == null) {
        return PackManager.pushOldPacks(project_id, doc_id, handler);
      } else {
        return PackManager.processOldPack(project_id, doc_id, _id, handler);
      }
    }, function(err, results) {
      if ((err != null) && err.message !== "shutdown") {
        logger.error({
          err: err
        }, 'error in pack archive worker processUpdates');
      }
      return finish();
    });
  };

  ObjectIdFromDate = function(date) {
    var id;
    id = Math.floor(date.getTime() / 1000).toString(16) + "0000000000000000";
    return ObjectId(id);
  };

  if (pending != null) {
    logger.log("got " + pending.length + " entries from " + source);
    processUpdates(pending);
  } else {
    oneWeekAgo = new Date(Date.now() - 7 * DAYS);
    db.docHistory.find({
      expiresAt: {
        $exists: false
      },
      project_id: {
        $exists: true
      },
      v_end: {
        $exists: true
      },
      _id: {
        $lt: ObjectIdFromDate(oneWeekAgo)
      },
      last_checked: {
        $lt: oneWeekAgo
      }
    }, {
      _id: 1,
      doc_id: 1,
      project_id: 1
    }).sort({
      last_checked: 1
    }).limit(LIMIT, function(err, results) {
      if (err != null) {
        logger.log({
          err: err
        }, 'error checking for updates');
        finish();
        return;
      }
      pending = _.uniq(results, false, function(result) {
        return result.doc_id.toString();
      });
      TOTAL = pending.length;
      logger.log("found " + TOTAL + " documents to archive");
      return processUpdates(pending);
    });
  }

}).call(this);

//# sourceMappingURL=PackWorker.js.map
